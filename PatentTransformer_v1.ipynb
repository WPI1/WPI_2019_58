{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PatentTransformer-v1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2dMuHFhsQEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "e6966a7c-bd7e-44ab-f561-10d26e176257"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "\n",
        "proj_folder = '/content/gpt-2'\n",
        "git_src = 'https://github.com/openai/gpt-2' \n",
        "if not os.path.exists(proj_folder):\n",
        "  !git clone $git_src\n",
        "else:\n",
        "  print('existed: %s' % proj_folder)\n",
        "  os.chdir(proj_folder)  \n",
        "  !git pull origin master\n",
        "\n",
        "os.chdir(proj_folder)\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 230 (delta 0), reused 1 (delta 0), pack-reused 227\u001b[K\n",
            "Receiving objects: 100% (230/230), 4.38 MiB | 2.99 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=c4720b199661c4d727a0a6d4a7b9421ebfcb512871a3cf58ff062b09b1b01298\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533172 sha256=4d7431098610ebe6c44d5105b27701821de1686ac32436f6b439d477ce530e93\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm\n",
            "  Found existing installation: regex 2019.12.9\n",
            "    Uninstalling regex-2019.12.9:\n",
            "      Successfully uninstalled regex-2019.12.9\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZJwuWIJsQI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "66c795b6-c4ab-4ce3-c3e8-2da48a7da089"
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "print('tf version: %s' % tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if 'GPU' in device_name:\n",
        "  print('GPU ready: %s' % device_name) \n",
        "  GPU_FLAG = True\n",
        "else:\n",
        "  print('CPU only.....')    \n",
        "\n",
        "src_path = '/content/gpt-2/src'\n",
        "if src_path not in sys.path:\n",
        "  sys.path += [src_path]\n",
        "\n",
        "os.chdir(proj_folder)\n",
        "model_name= '345M'  \n",
        "if os.path.exists(os.path.join('models', model_name)) == False:\n",
        "  print('download model %s....' % model_name)\n",
        "  !PYTHONPATH=src; python ./download_model.py $model_name\n",
        "else:\n",
        "  print('existed: model %s' % model_name)    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf version: 1.15.0\n",
            "GPU ready: /device:GPU:0\n",
            "download model 345M....\n",
            "Fetching checkpoint: 1.00kit [00:00, 873kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 41.9Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 674kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:34, 40.6Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 7.70Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 41.9Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 32.6Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9C9lZ6jgrCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the following code is copied from: \n",
        "# https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "    save_response_content(response, destination)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI-rkoeYTWFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9b7c82f1-c126-48b9-e430-0c901d99dbd9"
      },
      "source": [
        "# donwload fine-tuned model for patents\n",
        "\n",
        "ckpt_path = 'saved_checkpoint'\n",
        "if os.path.exists(ckpt_path):\n",
        "  print('Existed: %s' % ckpt_path)\n",
        "  !ls $ckpt_path\n",
        "else:\n",
        "  os.mkdir(ckpt_path)\n",
        "  os.chdir(ckpt_path)\n",
        "  print('Downloading files to %s....' % ckpt_path)\n",
        "  download_file_from_google_drive('10Qc8SIuwq6w6guwDnpdNzKH24NxZ3oG-', 'checkpoint')\n",
        "  download_file_from_google_drive('1KDO8ikS5IJqo1S6zfbOnFae3-zS6-8f0', 'model-945000.meta')\n",
        "  download_file_from_google_drive('1Z0PnW0BHFApZBBWL3SGDzwgFme1mwFwi', 'model-945000.data-00000-of-00001')\n",
        "  download_file_from_google_drive('1ipOdKVOUM8h45njLLtbhJFbfqTNFLNq_', 'model-945000.index')\n",
        "  !ls -al \n",
        "  print('Download: ok')\n",
        "os.chdir(proj_folder)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading files to saved_checkpoint....\n",
            "total 1393592\n",
            "drwxr-xr-x 2 root root       4096 Jan  6 07:34 .\n",
            "drwxr-xr-x 6 root root       4096 Jan  6 07:34 ..\n",
            "-rw-r--r-- 1 root root        253 Jan  6 07:34 checkpoint\n",
            "-rw-r--r-- 1 root root 1419292672 Jan  6 07:34 model-945000.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root      10399 Jan  6 07:34 model-945000.index\n",
            "-rw-r--r-- 1 root root    7715712 Jan  6 07:34 model-945000.meta\n",
            "Download: ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiBKgo1SsQWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ed3488b-38fb-4e73-aa95-272589a930c7"
      },
      "source": [
        "# the following is my enchancement based on: \n",
        "# https://github.com/openai/gpt-2/blob/master/src/sample.py\n",
        "# https://github.com/openai/gpt-2/blob/master/src/interactive_conditional_samples.py\n",
        "\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import model, sample, encoder\n",
        "\n",
        "def generate_text(seed_text, sess, output, context, nsamples, batch_size):\n",
        "    generated = 0\n",
        "    for _ in range(nsamples // batch_size):\n",
        "      out = sess.run(output, feed_dict={\n",
        "          context: [context_tokens for _ in range(batch_size)]\n",
        "      })[:, len(context_tokens):]\n",
        "      for i in range(batch_size):\n",
        "        generated += 1\n",
        "        text = enc.decode(out[i])\n",
        "        text = till_end_of_text(text)\n",
        "        text = seed_text + ' ' + text\n",
        "        print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "        text = text.replace(tag_start, '').strip()\n",
        "        span_text = text.replace(' @@@ ','\\n    ')\n",
        "        print(span_text)\n",
        "    print(\"=\" * 80)\n",
        "    print('\\n')\n",
        "\n",
        "def dynamic_kp_logits(logits, top_kp):\n",
        "    k = 1000 # observe probability of the top n \n",
        "    probs_logits = tf.nn.softmax(logits)\n",
        "    k_probs, _ = tf.nn.top_k(probs_logits, k=k)\n",
        "    k_probs = tf.squeeze(k_probs)\n",
        "    probs_max = tf.reduce_max(k_probs)\n",
        "    k_threshold = tf.multiply(probs_max, top_kp)\n",
        "    probs_mask = tf.to_int32(k_probs >= k_threshold)\n",
        "    num_of_k = tf.count_nonzero(probs_mask, dtype=tf.float32) \n",
        "\n",
        "    values, _ = tf.nn.top_k(logits, k=tf.cast(num_of_k, dtype=tf.int32))\n",
        "    min_values = values[:, -1, tf.newaxis]\n",
        "    result_logits = tf.where(\n",
        "        logits < min_values,\n",
        "        tf.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
        "        logits,)\n",
        "\n",
        "    return result_logits\n",
        "\n",
        "def sample_sequence_kp(*, hparams, length, start_token=None, batch_size=None, \n",
        "                       context=None, temperature=1, top_kp=0.1):\n",
        "    if start_token is None:\n",
        "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
        "    else:\n",
        "        assert context is None, 'Specify exactly one of start_token and context!'\n",
        "        context = tf.fill([batch_size, 1], start_token)\n",
        "\n",
        "    def step(hparams, tokens, past=None):\n",
        "        lm_output = model.model(hparams=hparams, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n",
        "\n",
        "        logits = lm_output['logits'][:, :, :hparams.n_vocab]\n",
        "        presents = lm_output['present']\n",
        "        presents.set_shape(model.past_shape(hparams=hparams, batch_size=batch_size))\n",
        "        return {\n",
        "            'logits': logits,\n",
        "            'presents': presents,\n",
        "        }\n",
        "\n",
        "    with tf.name_scope('sample_sequence'):\n",
        "        def body(past, prev, output):\n",
        "            next_outputs = step(hparams, prev, past=past)\n",
        "            logits = next_outputs['logits'][:, -1, :]  / tf.to_float(temperature)\n",
        "            logits = dynamic_kp_logits(logits, top_kp)\n",
        "            samples = tf.multinomial(logits, num_samples=1, output_dtype=tf.int32)\n",
        "            return [\n",
        "                next_outputs['presents'] if past is None else tf.concat([past, next_outputs['presents']], axis=-2),\n",
        "                samples,\n",
        "                tf.concat([output, samples], axis=1)\n",
        "            ]\n",
        "\n",
        "        past, prev, output = body(None, context, context)\n",
        "\n",
        "        def cond(*args):\n",
        "            return True\n",
        "\n",
        "        _, _, tokens = tf.while_loop(\n",
        "            cond=cond, body=body,\n",
        "            maximum_iterations=length - 1,\n",
        "            loop_vars=[\n",
        "                past,\n",
        "                prev,\n",
        "                output\n",
        "            ],\n",
        "            shape_invariants=[\n",
        "                tf.TensorShape(model.past_shape(hparams=hparams, batch_size=batch_size)),\n",
        "                tf.TensorShape([batch_size, None]),\n",
        "                tf.TensorShape([batch_size, None]),\n",
        "            ],\n",
        "            back_prop=False,\n",
        "        )\n",
        "\n",
        "        return tokens\n",
        "\n",
        "def till_end_of_text(text):\n",
        "  tag_end = '<|endoftext|>'\n",
        "  result = ''\n",
        "  pos2 = text.find(tag_end)\n",
        "  if pos2 == -1:\n",
        "    result = '(unable to generate....probably not patent text)'\n",
        "  elif pos2 == 0:\n",
        "    result = '(end of patent claim)'\n",
        "  else:\n",
        "    result = text[:pos2].strip()\n",
        "\n",
        "  return result\n",
        "\n",
        "# main program\n",
        "model_name='345M'\n",
        "seed=None\n",
        "nsamples=1\n",
        "batch_size=1\n",
        "length=None\n",
        "temperature=1\n",
        "top_k=40\n",
        "top_p=0.9\n",
        "top_kp=0.1\n",
        "\n",
        "tag_start = '<|startoftext|>'\n",
        "\n",
        "models_dir = 'models'\n",
        "models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "if batch_size is None:\n",
        "  batch_size = 1\n",
        "assert nsamples % batch_size == 0\n",
        "\n",
        "enc = encoder.get_encoder(model_name, models_dir)\n",
        "hparams = model.default_hparams()\n",
        "with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "  hparams.override_from_dict(json.load(f))\n",
        "\n",
        "if length is None:\n",
        "  length = hparams.n_ctx // 2\n",
        "elif length > hparams.n_ctx:\n",
        "  raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "  context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "  np.random.seed(seed)\n",
        "  tf.set_random_seed(seed)\n",
        "\n",
        "  # original sampling in GPT-2\n",
        "  output_top_k = sample.sample_sequence(\n",
        "    hparams=hparams, length=length,\n",
        "    context=context,\n",
        "    batch_size=batch_size,\n",
        "    temperature=temperature, top_k=top_k, top_p=1)\n",
        "  output_top_p = sample.sample_sequence(\n",
        "    hparams=hparams, length=length,\n",
        "    context=context,\n",
        "    batch_size=batch_size,\n",
        "    temperature=temperature, top_k=0, top_p=top_p)\n",
        "  \n",
        "  # a different sampling in our research\n",
        "  output_top_kp = sample_sequence_kp(\n",
        "    hparams=hparams, length=length,\n",
        "    context=context,\n",
        "    batch_size=batch_size,\n",
        "    temperature=temperature, top_kp=top_kp)\n",
        "\n",
        "  saver = tf.train.Saver()\n",
        "\n",
        "  # use the fine-tuned model for patents\n",
        "  ckpt = tf.train.latest_checkpoint(ckpt_path)\n",
        "\n",
        "  # original model released by OpenAI\n",
        "  # ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "\n",
        "  saver.restore(sess, ckpt)\n",
        "  while True:\n",
        "    print('Input text or \"exit\" or \"Enter\" key for unconditional sampling.....')\n",
        "    seed_text = input(\">>> \")\n",
        "    if seed_text == 'exit':\n",
        "      break\n",
        "    if seed_text == '':\n",
        "      seed_text = tag_start \n",
        "    context_tokens = enc.encode(seed_text)\n",
        "    print('top_k = %s' % top_k)\n",
        "    generate_text(seed_text, sess, output_top_k, context, nsamples, batch_size)\n",
        "    print('top_p = %s' % top_p)\n",
        "    generate_text(seed_text, sess, output_top_p, context, nsamples, batch_size)\n",
        "    print('top_kp = %s' % top_kp)\n",
        "    generate_text(seed_text, sess, output_top_kp, context, nsamples, batch_size)\n",
        "\n",
        "  print('Thank you.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-dab6998a8062>:33: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Restoring parameters from saved_checkpoint/model-945000\n",
            "Input text or \"exit\" or \"Enter\" key for unconditional sampling.....\n",
            ">>> A deep learning method for\n",
            "top_k = 40\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A deep learning method for deep reinforcement learning of an automatic speech recognizer system, the method comprising acts of:\n",
            "    determining acoustic feature parameters representing a phoneme structure of an input speech, based on a dictionary input;\n",
            "    training, using a learning algorithm implemented within the automatic speech recognizer system, a plurality of layers of CNNs for deep reinforcement learning of the automatic speech recognizer system, based on the determined acoustic feature parameters;\n",
            "    calculating, using a CNN implementation within the automatic speech recognizer system and based on the trained plurality of CNNs, a first plurality of weights for a particular CNN from the trained plurality of CNNs to be used for updating the particular output speech model, at each of a plurality of steps in a single-stepped CNN training process, and\n",
            "    calculating a second plurality of weights for the particular CNN on a particular update cycle, while continuing to use the particular output speech model maintained by the particular CNN for the particular update cycle as the particular trained CNN;\n",
            "    calculating, based on the first and second plurality of weights, a target probability of the transition probability taking into account a difference between a current target and a previous target from the certain plurality of CNNs; and\n",
            "    operating on the given output speech model maintained by the particular CNN within the particular one update cycle in the single-stepped CNN training process by applying the particular output speech model at the certain step, as a classifier output of the given speech model, the operation using the particular output speech model at the certain step, as the target probability for transition taking into account the difference between the current target and the previous target.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "top_p = 0.9\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A deep learning method for converting source data which includes a plurality of objects, comprising the steps of:\n",
            "    a) providing a deep neural network having a plurality of pairs of perceptimetric squares, an input for each perceptimetric square being an object and a parameter representing the object's properties;\n",
            "    b) generating subspace pairs for the object from a plurality of the perceptimetric squares by superimposing the object onto the perceptimetric square corresponding to the object;\n",
            "    c) generating a subspace matrix by superimposing the subspace pairs generated in step b);\n",
            "    d) generating the parameters for the object by applying the subspace matrix to the input for each perceptimetric square;\n",
            "    e) providing a column-indexed list of reference data by appending the parameters to a current perceptimetric square;\n",
            "    f) computing a strength metric from the list of reference data and the current perceptimetric square;\n",
            "    g) selecting the object from the list of reference data by computing a sum of the strength metric and an identity metric of the selection of the object; and\n",
            "    h) determining the properties of the object from the current perceptimetric square and the selection of the object by applying a Bayesian network based decision process to determine the properties of the object based on the current perceptimetric square and selection of the object.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "top_kp = 0.1\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A deep learning method for representing a set of training data sets and associated training data set weights using a deep learning ensemble, each training data set being a set of pixel values and associated weighting coefficients, wherein the deep learning ensemble comprises a set of training data sets, each training data set comprising training data values, and\n",
            "    wherein the deep learning method comprises:\n",
            "    assigning weights to the training data sets of the deep learning ensemble, wherein the weights are based on one or more characteristics of the training data set, and\n",
            "    wherein the training data set characteristics include at least one of: the size of the training data set, the number of columns of the training data set, and\n",
            "    the type of the training data set;\n",
            "    generating a plurality of learning sets based on the training data sets of the deep learning ensemble, each learning set comprising a respective subset of the training data sets of the deep learning ensemble, wherein the plurality of learning sets have associated weights assigned thereto;\n",
            "    learning, from each training data set of the plurality of learning sets, a respective subset of training data values of each training data set of the plurality of learning sets;\n",
            "    generating a respective set of weights corresponding to each training data set of the plurality of training sets based on the training data values and the training data set characteristics; and\n",
            "    generating a respective ensemble of weights based on the respective set of weights and the respective subset of training data values of each training data set of the plurality of training sets, wherein each training data set of the ensemble comprises a respective subset of training data values and a respective set of weighting coefficients, and\n",
            "    wherein each training data set of the ensemble is a respective subset of training data values.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Input text or \"exit\" or \"Enter\" key for unconditional sampling.....\n",
            ">>> \n",
            "top_k = 40\n",
            "======================================== SAMPLE 1 ========================================\n",
            "In a device for automatically monitoring and controlling the movement of an airborne aircraft (AA) through the operation of at least one sensor (22) comprising:\n",
            "    at least one sensor (22) being connected to a control unit (20), a processor unit (20) and communicating means (24) for the sensor (22),\n",
            "    said control unit (20) having a central processing unit (CPU) (20) including a microprocessor (30) as a controller of the unit, a communication port (31) for the communication means, an onboard storage unit (32) storing a plurality of sensors (22) and the operational status of all of them, a local memory unit (33) for the communication with said at least one sensor (22), computer access storage unit (34) storing multiple independent unit systems and the operational status of each of them, a user interface (35) for the pilot (28) to transmit the necessary command, the sensor data from each and every sensor (22) received from said at least one sensor (22), and\n",
            "    external memory unit (36) for the user interface and said at least one user interface,\n",
            "    said at least one sensor (22) being one of an altitude sensor (22) and a relative bearing sensor (22) having a transmitter (29) with an antenna (30), the transmitter (29) communicating with the communication means (24) and a receiver (36) to receive the command signals, transmission signal to said receiver (36) for the processor unit (20) and to generate commands for the microprocessor (30) to thereby adjust sensor signals to the movements of aircraft (AA) of the AA's flying over the same airspace,\n",
            "    the unit (20) is a GPS-based unit, the GPS unit unit (20) receives satellite signals and said satellite signals carry position and speed information in addition to altitude data, and\n",
            "    the processor unit (20) also receives said altitude data and said position and speed information from the satellite systems and the altitude data from one or more satellites and calculates the relative bearing of the aircraft (AA) by the calculation of the altitude data divided by the fraction of the altitude data that is due to said relative bearing sensor data.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "top_p = 0.9\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A light emitting element package comprising:\n",
            "    a housing having a base, a first heat sink attached to the base, and\n",
            "    a second heat sink attached to the base, wherein the first and second heat sinks are substantially perpendicular to each other, and\n",
            "    a light emitting element disposed on the first heat sink;\n",
            "    a resin case received in the housing and having a first area and a second area;\n",
            "    a plurality of metal leads extending from the first area and connecting with the first heat sink;\n",
            "    a plurality of metal terminals extending from the second area and connecting with the second heat sink;\n",
            "    a glass layer covering the light emitting element and the plurality of metal terminals, and\n",
            "    having a concave portion formed on an inner surface; and\n",
            "    a substrate disposed on the concave portion of the glass layer and having a plurality of third leads extending from the first area and connecting with the second heat sink.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "top_kp = 0.1\n",
            "======================================== SAMPLE 1 ========================================\n",
            "A method for processing a data stream having a first and second data stream channels, comprising:\n",
            "    determining an initial delay value for the data stream, the initial delay value being a clock value and having a fixed duration;\n",
            "    generating a delay value for the data stream at least in part, based upon the initial delay value, the delay value being a clock value, the delay value being a multiple of the clock value of the initial delay value, the delay value being less than a full delay value; and\n",
            "    applying the delay value to the data stream for adjusting the data stream channel for processing, the applying comprising changing the data stream channel in part to the delay value.\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Input text or \"exit\" or \"Enter\" key for unconditional sampling.....\n",
            ">>> exit\n",
            "Thank you.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ikNAbesQSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}